{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubj7DataSkP8"
   },
   "source": [
    "### **Projects in Advanced Machine Learning**\n",
    "#### **GR5074**\n",
    "#### **Homework 3**\n",
    "#### **Cecilia Cabello Esquer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAfUrqUoR9LR"
   },
   "source": [
    "**Instructions:**\n",
    "\n",
    "**(Use the BBC News Category Classification Notebook in the Week 12 folder to import data for this assignment)**\n",
    "\n",
    "**Your final report should be written up in a Jupyter notebook. It should be posted to a public Github repo as an ipynb AND it should be saved as an html file and submitted to this assignment via courseworks. Please include the link to your Github repo in this html file.**\n",
    "\n",
    "**Your report should include the following information:**\n",
    "\n",
    "**(Note: Be sure to split your data into training and test sets after importing the csv file with pandas. You can use sklearn's train_test_split() function to split your data. )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "gIlAyeNGf6tx",
    "outputId": "d8a65724-d330-4509-8b5d-5ba89f8bf9c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfhumCQ3xZkg"
   },
   "outputs": [],
   "source": [
    "# From\n",
    "## Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "## Split train_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "## Models\n",
    "### All\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "### Conv1D Layers\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "### GRU/LSTM\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "\n",
    "### Bidirectional\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33syq7-Bzwv_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "RwqEWDONSh51",
    "outputId": "040da1e7-1b4e-4036-ba3f-6e37dbcdb318"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abrir datos\n",
    "data= pd.read_csv(\"https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDAGFXlLR_v9"
   },
   "source": [
    "## **1) Visualize the categories of your target variable and describe the dataset generally (the data includes news articles from the BBC news.) A simple description is fine.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thWvnK_84keD"
   },
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ve1JmX6L67jG"
   },
   "source": [
    "Understanding the database and variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "Q8uj0SPdu0BI",
    "outputId": "12a570f9-0eea-4604-c026-4696eda0bc27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count unique                                                top freq\n",
      "category  2225      5                                              sport  511\n",
      "text      2225   2126  apple ipod family expands market apple has exp...    2\n",
      "\n",
      "sport            511\n",
      "business         510\n",
      "politics         417\n",
      "tech             401\n",
      "entertainment    386\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Description of categorical variables\n",
    "print(data.describe().transpose())\n",
    "print( )\n",
    "print(data['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "9OudvStL64Eg",
    "outputId": "f959b78d-1114-4c7a-a9ae-3883b8bc42d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.groupby('category').count().plot.bar()\n",
    "plt.title(\"Absolute frequency of categories\")\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "1yUBLq1U5z88",
    "outputId": "5c664504-34af-4062-d9c2-acaeb9ed1312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             words   characters\n",
      "count  2225.000000   2225.00000\n",
      "mean    390.295281   2262.93618\n",
      "std     241.753128   1364.10253\n",
      "min      90.000000    501.00000\n",
      "25%     250.000000   1446.00000\n",
      "50%     337.000000   1965.00000\n",
      "75%     479.000000   2802.00000\n",
      "max    4492.000000  25483.00000\n"
     ]
    }
   ],
   "source": [
    "data['words']= data['text'].apply(lambda x: len(x.split()))\n",
    "data['characters']= data['text'].apply(lambda x: len(x))\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "FVfiM13z7wEI",
    "outputId": "95b2c28e-1c33-47f7-c367-557f6710c952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of number of characters per text')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn= sns.distplot(data['characters'], hist=True, kde=False, \n",
    "            axlabel= \"Number of words\")\n",
    "sn.set_title(\"Histogram of number of characters per text\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Tdw7i6lQ7sSO",
    "outputId": "a5ba4b7e-28b6-46be-8f95-8f15e526d924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of number of words per text')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn= sns.distplot(data['words'], hist=True, kde=False, \n",
    "            axlabel= \"Number of words\")\n",
    "sn.set_title(\"Histogram of number of words per text\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTJ5QWKoSLxc"
   },
   "source": [
    "## **2) Preprocess your data such that each document in the data is represented as a sequence of equal length.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "1JGhcC9W_RCC",
    "outputId": "7844cb15-d72d-42d7-e8f0-430606f6d4c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= data[['category', 'text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gZZfja3RgRY"
   },
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2pV64L7RKXJ"
   },
   "source": [
    "Preprocessing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "1sqyTmuuRM96",
    "outputId": "eba4221f-9630-45da-970f-682ffa9a9612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29726 unique tokens.\n",
      "(2225, 100)\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data intto one hot vectors\n",
    "\n",
    "maxlen = 100\n",
    "training_samples = 200  \n",
    "validation_samples = 10000 \n",
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X) \n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen) \n",
    "\n",
    "labels = np.asarray(pd.get_dummies(y))\n",
    "print(data.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7V4J135JYqe"
   },
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "SjP6J2DIJXlQ",
    "outputId": "bffff0e0-546c-428a-b170-f266c28acade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1668, 100)\n",
      "(1668, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmPDmauYSPM1"
   },
   "source": [
    "**3) Use the data to fit separate models to each of the following architectures:**\n",
    "\n",
    "**A. A model with an embedding layer and dense layers (but w/ no layers meant for sequential data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YtlU9Z_0dFfi",
    "outputId": "9269c749-e049-4dff-f18c-7f656d719bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               4000200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 6,001,205\n",
      "Trainable params: 6,001,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1334 samples, validate on 334 samples\n",
      "Epoch 1/20\n",
      "1334/1334 [==============================] - 0s 364us/step - loss: 1.6461 - acc: 0.2511 - val_loss: 1.5632 - val_acc: 0.3383\n",
      "Epoch 2/20\n",
      "1334/1334 [==============================] - 0s 106us/step - loss: 1.3209 - acc: 0.5420 - val_loss: 1.4575 - val_acc: 0.4281\n",
      "Epoch 3/20\n",
      "1334/1334 [==============================] - 0s 99us/step - loss: 0.9592 - acc: 0.9483 - val_loss: 1.2672 - val_acc: 0.6347\n",
      "Epoch 4/20\n",
      "1334/1334 [==============================] - 0s 95us/step - loss: 0.5763 - acc: 0.9933 - val_loss: 1.0612 - val_acc: 0.7126\n",
      "Epoch 5/20\n",
      "1334/1334 [==============================] - 0s 92us/step - loss: 0.2806 - acc: 0.9993 - val_loss: 0.8975 - val_acc: 0.7425\n",
      "Epoch 6/20\n",
      "1334/1334 [==============================] - 0s 94us/step - loss: 0.1283 - acc: 1.0000 - val_loss: 0.7731 - val_acc: 0.7904\n",
      "Epoch 7/20\n",
      "1334/1334 [==============================] - 0s 87us/step - loss: 0.0620 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.7994\n",
      "Epoch 8/20\n",
      "1334/1334 [==============================] - 0s 83us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.6481 - val_acc: 0.8024\n",
      "Epoch 9/20\n",
      "1334/1334 [==============================] - 0s 83us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6208 - val_acc: 0.8054\n",
      "Epoch 10/20\n",
      "1334/1334 [==============================] - 0s 85us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6042 - val_acc: 0.8084\n",
      "Epoch 11/20\n",
      "1334/1334 [==============================] - 0s 83us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.8144\n",
      "Epoch 12/20\n",
      "1334/1334 [==============================] - 0s 86us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.5835 - val_acc: 0.8144\n",
      "Epoch 13/20\n",
      "1334/1334 [==============================] - 0s 88us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5760 - val_acc: 0.8144\n",
      "Epoch 14/20\n",
      "1334/1334 [==============================] - 0s 91us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5696 - val_acc: 0.8144\n",
      "Epoch 15/20\n",
      "1334/1334 [==============================] - 0s 84us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5642 - val_acc: 0.8174\n",
      "Epoch 16/20\n",
      "1334/1334 [==============================] - 0s 84us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5592 - val_acc: 0.8174\n",
      "Epoch 17/20\n",
      "1334/1334 [==============================] - 0s 83us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5541 - val_acc: 0.8174\n",
      "Epoch 18/20\n",
      "1334/1334 [==============================] - 0s 86us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5495 - val_acc: 0.8174\n",
      "Epoch 19/20\n",
      "1334/1334 [==============================] - 0s 85us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5454 - val_acc: 0.8174\n",
      "Epoch 20/20\n",
      "1334/1334 [==============================] - 0s 84us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5417 - val_acc: 0.8174\n",
      "557/557 [==============================] - 0s 92us/step\n",
      "Test score: 0.6307635309452214\n",
      "Test accuracy: 0.7791741490364075\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200, activation=\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer= \"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=200,\n",
    "                    validation_split= 0.2)\n",
    "\n",
    "score, acc =model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEUutDKYSSsX"
   },
   "source": [
    "**B. A model using an Embedding layer with Conv1d Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1mOedwoiStAq",
    "outputId": "05dc628e-8eb7-476f-a7fa-545c64dfa6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 94, 200)           280200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 18, 200)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               720200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 3,001,405\n",
      "Trainable params: 3,001,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1334 samples, validate on 334 samples\n",
      "Epoch 1/20\n",
      "1334/1334 [==============================] - 1s 960us/step - loss: 1.6294 - acc: 0.2099 - val_loss: 1.5878 - val_acc: 0.2455\n",
      "Epoch 2/20\n",
      "1334/1334 [==============================] - 0s 178us/step - loss: 1.5422 - acc: 0.3921 - val_loss: 1.5492 - val_acc: 0.4192\n",
      "Epoch 3/20\n",
      "1334/1334 [==============================] - 0s 175us/step - loss: 1.4013 - acc: 0.6672 - val_loss: 1.3902 - val_acc: 0.5749\n",
      "Epoch 4/20\n",
      "1334/1334 [==============================] - 0s 173us/step - loss: 1.0410 - acc: 0.8141 - val_loss: 1.0034 - val_acc: 0.7006\n",
      "Epoch 5/20\n",
      "1334/1334 [==============================] - 0s 171us/step - loss: 0.5721 - acc: 0.9363 - val_loss: 0.6301 - val_acc: 0.8383\n",
      "Epoch 6/20\n",
      "1334/1334 [==============================] - 0s 171us/step - loss: 0.2240 - acc: 0.9798 - val_loss: 0.4056 - val_acc: 0.8623\n",
      "Epoch 7/20\n",
      "1334/1334 [==============================] - 0s 177us/step - loss: 0.0674 - acc: 0.9955 - val_loss: 0.2936 - val_acc: 0.8862\n",
      "Epoch 8/20\n",
      "1334/1334 [==============================] - 0s 172us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.2569 - val_acc: 0.9042\n",
      "Epoch 9/20\n",
      "1334/1334 [==============================] - 0s 172us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2811 - val_acc: 0.8952\n",
      "Epoch 10/20\n",
      "1334/1334 [==============================] - 0s 176us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.2861 - val_acc: 0.8892\n",
      "Epoch 11/20\n",
      "1334/1334 [==============================] - 0s 178us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2688 - val_acc: 0.9042\n",
      "Epoch 12/20\n",
      "1334/1334 [==============================] - 0s 169us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.9072\n",
      "Epoch 13/20\n",
      "1334/1334 [==============================] - 0s 171us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9102\n",
      "Epoch 14/20\n",
      "1334/1334 [==============================] - 0s 171us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2662 - val_acc: 0.9012\n",
      "Epoch 15/20\n",
      "1334/1334 [==============================] - 0s 171us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.2710 - val_acc: 0.9012\n",
      "Epoch 16/20\n",
      "1334/1334 [==============================] - 0s 172us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2745 - val_acc: 0.9012\n",
      "Epoch 17/20\n",
      "1334/1334 [==============================] - 0s 174us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 0.9042\n",
      "Epoch 18/20\n",
      "1334/1334 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2774 - val_acc: 0.9042\n",
      "Epoch 19/20\n",
      "1334/1334 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2772 - val_acc: 0.9042\n",
      "Epoch 20/20\n",
      "1334/1334 [==============================] - 0s 176us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2769 - val_acc: 0.8982\n",
      "557/557 [==============================] - 0s 171us/step\n",
      "Test score: 0.32324955027878177\n",
      "Test accuracy: 0.8904847502708435\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200, input_length=maxlen))\n",
    "model.add(Conv1D(200, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200, activation=\"sigmoid\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer= \"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=200,\n",
    "                    validation_split= 0.2)\n",
    "\n",
    "score, acc =model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qn7hbmVRSUjy"
   },
   "source": [
    "**C. A model using an Embedding layer with one sequential layer (LSTM or GRU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6vif73HOStlb",
    "outputId": "2f236239-b6df-41da-fdfe-f4f5b0ec40d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 2,362,005\n",
      "Trainable params: 2,362,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1334 samples, validate on 334 samples\n",
      "Epoch 1/20\n",
      "1334/1334 [==============================] - 2s 2ms/step - loss: 1.6168 - acc: 0.2114 - val_loss: 1.5948 - val_acc: 0.2485\n",
      "Epoch 2/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 1.5846 - acc: 0.2429 - val_loss: 1.4527 - val_acc: 0.2814\n",
      "Epoch 3/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 1.3852 - acc: 0.3898 - val_loss: 1.3927 - val_acc: 0.4042\n",
      "Epoch 4/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 1.2412 - acc: 0.4220 - val_loss: 1.3331 - val_acc: 0.4341\n",
      "Epoch 5/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 1.1386 - acc: 0.4580 - val_loss: 1.1777 - val_acc: 0.4251\n",
      "Epoch 6/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 1.1002 - acc: 0.4865 - val_loss: 1.1532 - val_acc: 0.6257\n",
      "Epoch 7/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.9996 - acc: 0.6019 - val_loss: 0.9988 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.8946 - acc: 0.6732 - val_loss: 0.8484 - val_acc: 0.7066\n",
      "Epoch 9/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.6494 - acc: 0.8006 - val_loss: 0.7141 - val_acc: 0.7216\n",
      "Epoch 10/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.4722 - acc: 0.8523 - val_loss: 0.6939 - val_acc: 0.6886\n",
      "Epoch 11/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.4155 - acc: 0.8396 - val_loss: 0.8380 - val_acc: 0.6826\n",
      "Epoch 12/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.2920 - acc: 0.9055 - val_loss: 0.5714 - val_acc: 0.7844\n",
      "Epoch 13/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.1548 - acc: 0.9738 - val_loss: 0.5913 - val_acc: 0.8084\n",
      "Epoch 14/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.1034 - acc: 0.9745 - val_loss: 0.4495 - val_acc: 0.8683\n",
      "Epoch 15/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.0981 - acc: 0.9745 - val_loss: 0.4189 - val_acc: 0.8533\n",
      "Epoch 16/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.0474 - acc: 0.9955 - val_loss: 0.3527 - val_acc: 0.8892\n",
      "Epoch 17/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.0294 - acc: 0.9948 - val_loss: 0.4762 - val_acc: 0.8533\n",
      "Epoch 18/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.0301 - acc: 0.9955 - val_loss: 0.4343 - val_acc: 0.8413\n",
      "Epoch 19/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.0265 - acc: 0.9985 - val_loss: 0.3984 - val_acc: 0.8623\n",
      "Epoch 20/20\n",
      "1334/1334 [==============================] - 2s 1ms/step - loss: 0.0152 - acc: 0.9993 - val_loss: 0.4725 - val_acc: 0.8563\n",
      "557/557 [==============================] - 1s 913us/step\n",
      "Test score: 0.7169788649951107\n",
      "Test accuracy: 0.8114901185035706\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200, input_length=maxlen))\n",
    "model.add(LSTM(200))\n",
    "\n",
    "model.add(Dense(200, activation=\"sigmoid\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer= \"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=200,\n",
    "                    validation_split= 0.2)\n",
    "                    \n",
    "score, acc =model.evaluate(X_test, y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kN7FQ9XSW0E"
   },
   "source": [
    "**D. A model using an Embedding layer with stacked sequential layers (LSTM or GRU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bAuKlw_AqEDu",
    "outputId": "84958036-2190-4c62-b71e-99cb791b618d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 100, 200)          240600    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 200)               240600    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 2,522,405\n",
      "Trainable params: 2,522,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1334 samples, validate on 334 samples\n",
      "Epoch 1/20\n",
      "1334/1334 [==============================] - 5s 4ms/step - loss: 1.6600 - acc: 0.2286 - val_loss: 1.5938 - val_acc: 0.2275\n",
      "Epoch 2/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 1.5931 - acc: 0.2256 - val_loss: 1.5903 - val_acc: 0.2365\n",
      "Epoch 3/20\n",
      "1334/1334 [==============================] - 5s 4ms/step - loss: 1.5070 - acc: 0.3253 - val_loss: 1.4556 - val_acc: 0.3892\n",
      "Epoch 4/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 1.1470 - acc: 0.4618 - val_loss: 1.2839 - val_acc: 0.5240\n",
      "Epoch 5/20\n",
      "1334/1334 [==============================] - 5s 4ms/step - loss: 0.8014 - acc: 0.7654 - val_loss: 1.1005 - val_acc: 0.5808\n",
      "Epoch 6/20\n",
      "1334/1334 [==============================] - 5s 4ms/step - loss: 0.4913 - acc: 0.8741 - val_loss: 0.9984 - val_acc: 0.6707\n",
      "Epoch 7/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.2318 - acc: 0.9498 - val_loss: 1.0423 - val_acc: 0.7006\n",
      "Epoch 8/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.1197 - acc: 0.9708 - val_loss: 0.9459 - val_acc: 0.7395\n",
      "Epoch 9/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0547 - acc: 0.9940 - val_loss: 0.9336 - val_acc: 0.7545\n",
      "Epoch 10/20\n",
      "1334/1334 [==============================] - 5s 4ms/step - loss: 0.0309 - acc: 0.9940 - val_loss: 0.8542 - val_acc: 0.7784\n",
      "Epoch 11/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0195 - acc: 0.9978 - val_loss: 0.9889 - val_acc: 0.7575\n",
      "Epoch 12/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.0152 - val_acc: 0.7665\n",
      "Epoch 13/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9278 - val_acc: 0.7874\n",
      "Epoch 14/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.8926 - val_acc: 0.8024\n",
      "Epoch 15/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1425 - val_acc: 0.7395\n",
      "Epoch 16/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0214 - acc: 0.9940 - val_loss: 1.1529 - val_acc: 0.7515\n",
      "Epoch 17/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0154 - acc: 0.9978 - val_loss: 1.1238 - val_acc: 0.7335\n",
      "Epoch 18/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.3148 - val_acc: 0.6796\n",
      "Epoch 19/20\n",
      "1334/1334 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.2681 - val_acc: 0.6826\n",
      "Epoch 20/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0055 - acc: 0.9993 - val_loss: 1.2081 - val_acc: 0.7126\n",
      "557/557 [==============================] - 1s 2ms/step\n",
      "Test score: 1.4265837292696886\n",
      "Test accuracy: 0.6983842253684998\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200, input_length=maxlen))\n",
    "model.add(GRU(200, return_sequences= True))\n",
    "model.add(GRU(200))\n",
    "\n",
    "\n",
    "model.add(Dense(200, activation=\"sigmoid\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer= \"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=200,\n",
    "                    validation_split= 0.2)\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB1IeYooSZLs"
   },
   "source": [
    "**E. A model using an Embedding layer with bidirectional sequential layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sP82w6KrSvjn",
    "outputId": "e7650134-c054-41ad-f463-eedeff4421d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 400)               641600    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 2,722,805\n",
      "Trainable params: 2,722,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1334 samples, validate on 334 samples\n",
      "Epoch 1/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.8060 - acc: 0.1784 - val_loss: 1.5978 - val_acc: 0.2455\n",
      "Epoch 2/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.5992 - acc: 0.2421 - val_loss: 1.5768 - val_acc: 0.3683\n",
      "Epoch 3/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.5421 - acc: 0.2856 - val_loss: 1.4591 - val_acc: 0.2784\n",
      "Epoch 4/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.2267 - acc: 0.4153 - val_loss: 1.2188 - val_acc: 0.4311\n",
      "Epoch 5/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.9909 - acc: 0.5585 - val_loss: 0.8779 - val_acc: 0.6108\n",
      "Epoch 6/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.7469 - acc: 0.7039 - val_loss: 1.1477 - val_acc: 0.6677\n",
      "Epoch 7/20\n",
      "1334/1334 [==============================] - 3s 3ms/step - loss: 0.8132 - acc: 0.7196 - val_loss: 1.1085 - val_acc: 0.6138\n",
      "Epoch 8/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.8310 - acc: 0.7016 - val_loss: 1.2364 - val_acc: 0.5030\n",
      "Epoch 9/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.8470 - acc: 0.5975 - val_loss: 1.1607 - val_acc: 0.4431\n",
      "Epoch 10/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.7631 - acc: 0.6312 - val_loss: 1.0339 - val_acc: 0.6617\n",
      "Epoch 11/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.6639 - acc: 0.7564 - val_loss: 0.8960 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5078 - acc: 0.8291 - val_loss: 0.7450 - val_acc: 0.7096\n",
      "Epoch 13/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3656 - acc: 0.8733 - val_loss: 0.6449 - val_acc: 0.7725\n",
      "Epoch 14/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2797 - acc: 0.9348 - val_loss: 0.6692 - val_acc: 0.7425\n",
      "Epoch 15/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1940 - acc: 0.9625 - val_loss: 0.4827 - val_acc: 0.8263\n",
      "Epoch 16/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0892 - acc: 0.9858 - val_loss: 0.4651 - val_acc: 0.8503\n",
      "Epoch 17/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0532 - acc: 0.9910 - val_loss: 0.4785 - val_acc: 0.8323\n",
      "Epoch 18/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0730 - acc: 0.9783 - val_loss: 0.4034 - val_acc: 0.8533\n",
      "Epoch 19/20\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0609 - acc: 0.9948 - val_loss: 0.4809 - val_acc: 0.8323\n",
      "Epoch 20/20\n",
      "1334/1334 [==============================] - 3s 3ms/step - loss: 0.0392 - acc: 0.9985 - val_loss: 0.4477 - val_acc: 0.8413\n",
      "557/557 [==============================] - 1s 1ms/step\n",
      "Test score: 0.6074476411141442\n",
      "Test accuracy: 0.8204667568206787\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(200)))\n",
    "\n",
    "model.add(Dense(200, activation=\"sigmoid\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer= \"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=200,\n",
    "                    validation_split= 0.2)\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ps-7OEslSbZ7"
   },
   "source": [
    "**F. Now retrain your best model from C, D, and E using dropout (you may need to increase epochs!).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rT4mr9Arsfje"
   },
   "source": [
    "E + DROPOUT + EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iVByw4i2sjLu",
    "outputId": "ea1e924c-49c9-47e9-9fb8-7838db7acf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 400)               641600    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 2,722,805\n",
      "Trainable params: 2,722,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1334 samples, validate on 334 samples\n",
      "Epoch 1/30\n",
      "1334/1334 [==============================] - 5s 4ms/step - loss: 1.6698 - acc: 0.1972 - val_loss: 1.6189 - val_acc: 0.2216\n",
      "Epoch 2/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.6197 - acc: 0.2406 - val_loss: 1.5890 - val_acc: 0.2455\n",
      "Epoch 3/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.5599 - acc: 0.2616 - val_loss: 1.4353 - val_acc: 0.4371\n",
      "Epoch 4/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.3216 - acc: 0.4333 - val_loss: 1.2887 - val_acc: 0.4401\n",
      "Epoch 5/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 1.1511 - acc: 0.5862 - val_loss: 1.0819 - val_acc: 0.5749\n",
      "Epoch 6/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.8135 - acc: 0.6957 - val_loss: 0.8604 - val_acc: 0.6647\n",
      "Epoch 7/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5271 - acc: 0.8418 - val_loss: 0.7393 - val_acc: 0.7455\n",
      "Epoch 8/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3350 - acc: 0.9168 - val_loss: 0.4163 - val_acc: 0.8832\n",
      "Epoch 9/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1723 - acc: 0.9625 - val_loss: 0.5130 - val_acc: 0.8623\n",
      "Epoch 10/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1056 - acc: 0.9753 - val_loss: 0.4387 - val_acc: 0.8892\n",
      "Epoch 11/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1008 - acc: 0.9775 - val_loss: 0.4645 - val_acc: 0.8802\n",
      "Epoch 12/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0791 - acc: 0.9858 - val_loss: 0.4984 - val_acc: 0.8802\n",
      "Epoch 13/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1890 - acc: 0.9700 - val_loss: 0.5838 - val_acc: 0.7964\n",
      "Epoch 14/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1105 - acc: 0.9798 - val_loss: 0.7032 - val_acc: 0.8114\n",
      "Epoch 15/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1388 - acc: 0.9678 - val_loss: 1.2665 - val_acc: 0.7545\n",
      "Epoch 16/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.4646 - acc: 0.8306 - val_loss: 1.2785 - val_acc: 0.6617\n",
      "Epoch 17/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3898 - acc: 0.8186 - val_loss: 1.1685 - val_acc: 0.7126\n",
      "Epoch 18/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3664 - acc: 0.8456 - val_loss: 0.9963 - val_acc: 0.7066\n",
      "Epoch 19/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3358 - acc: 0.8771 - val_loss: 0.8489 - val_acc: 0.7605\n",
      "Epoch 20/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2196 - acc: 0.9355 - val_loss: 0.6945 - val_acc: 0.8024\n",
      "Epoch 21/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1457 - acc: 0.9625 - val_loss: 1.0358 - val_acc: 0.7695\n",
      "Epoch 22/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.1247 - acc: 0.9768 - val_loss: 0.8901 - val_acc: 0.8323\n",
      "Epoch 23/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0698 - acc: 0.9873 - val_loss: 0.6211 - val_acc: 0.8563\n",
      "Epoch 24/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0429 - acc: 0.9948 - val_loss: 0.4922 - val_acc: 0.8862\n",
      "Epoch 25/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0345 - acc: 0.9963 - val_loss: 0.4722 - val_acc: 0.8922\n",
      "Epoch 26/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0230 - acc: 0.9970 - val_loss: 0.5945 - val_acc: 0.8772\n",
      "Epoch 27/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0327 - acc: 0.9955 - val_loss: 0.7413 - val_acc: 0.8623\n",
      "Epoch 28/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0405 - acc: 0.9940 - val_loss: 0.8634 - val_acc: 0.8473\n",
      "Epoch 29/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0597 - acc: 0.9903 - val_loss: 0.8561 - val_acc: 0.8473\n",
      "Epoch 30/30\n",
      "1334/1334 [==============================] - 4s 3ms/step - loss: 0.0499 - acc: 0.9918 - val_loss: 0.7476 - val_acc: 0.8653\n",
      "557/557 [==============================] - 1s 1ms/step\n",
      "Test score: 0.6418340739056709\n",
      "Test accuracy: 0.8689407706260681\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(200, dropout=0.15)))\n",
    "\n",
    "model.add(Dense(200, activation=\"sigmoid\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer= \"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=30,\n",
    "                    batch_size=200,\n",
    "                    validation_split= 0.2)\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUSYqtLxSdrI"
   },
   "source": [
    "**4) Discuss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMJoF39KvHuk"
   },
   "source": [
    "**a) Which model(s) performed best**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KjSIIsYsvP10"
   },
   "source": [
    "Out of the three sequential models explore in this analysis the one with the best results was the bidirectional model, as would be expected since in such cases words are also read in the opposite direction. The same structure was followed when adding dropout of 0.15, while compensating its possible on overfitting by adding more epochs to our model (from 20 to 30).\n",
    "\n",
    "\n",
    "The next best model included a single sequential layer (LSTM) and a dense layer of 200 neurons. In contrast, the second most complicated model, stacked sequential layers (using GRUs) performed much more poorly. Which leads me to believe LSTM is better GRU in this particular case.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVsnc2-lvCWx"
   },
   "source": [
    "**b) how you might try to further improve the predictive power of your model (e.g. Glove embeddings? More layers? Combining Conv1D with LSTM layers? More LSTM hidden nodes?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rh5X5mjlvTAN"
   },
   "source": [
    "With regards to the embedding I would like to include pre-trained embeddings such as Glove and BagofWords, as their training is probabily more precise. I would also like to include more epochs and layer to my models, as well as to play with the dropout possibilites. In particular, dropout monitoring loss. \n",
    "And one combination that might give me more input on the effect of using GRU vs. LSTM would be to use staked LSTM layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3G5xW8Zu96S"
   },
   "source": [
    "**Repo link:** https://github.com/cecicabello/HW3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
